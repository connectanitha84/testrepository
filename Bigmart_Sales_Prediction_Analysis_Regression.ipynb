{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/connectanitha84/testrepository/blob/main/Bigmart_Sales_Prediction_Analysis_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYNIlcuWU4Eq"
      },
      "source": [
        "## Dataset Information - testing in github\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANpz3EznU4Es"
      },
      "source": [
        "The data scientists at BigMart have collected 2013 sales data for 1559 products across 10 stores in different cities. Also, certain attributes of each product and store have been defined. The aim is to build a predictive model and find out the sales of each product at a particular store.\n",
        "\n",
        "Using this model, BigMart will try to understand the properties of products and stores which play a key role in increasing sales.\n",
        "\n",
        "\n",
        "Variable | Description\n",
        "----------|--------------\n",
        "Item_Identifier | Unique product ID\n",
        "Item_Weight | Weight of product\n",
        "Item_Fat_Content | Whether the product is low fat or not\n",
        "Item_Visibility | The % of total display area of all products in a    store allocated to the particular product\n",
        "Item_Type | The category to which the product belongs\n",
        "Item_MRP | Maximum Retail Price (list price) of the product\n",
        "Outlet_Identifier | Unique store ID\n",
        "Outlet_Establishment_Year | The year in which store was established\n",
        "Outlet_Size | The size of the store in terms of ground area covered\n",
        "Outlet_Location_Type | The type of city in which the store is located\n",
        "Outlet_Type | Whether the outlet is just a grocery store or some sort of supermarket\n",
        "Item_Outlet_Sales | Sales of the product in the particulat store. This is the outcome variable to be predicted."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou2Bp2EDU4Et"
      },
      "source": [
        "## Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYRhRjoOU4Et"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "%matplotlib inline\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbEeGPOrU4Eu"
      },
      "source": [
        "## Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFqTEh-cU4Eu",
        "outputId": "fa3d4b76-a052-412b-af4c-a426e59ac046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-dff7785fcf5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bigmart-sales-Train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bigmart-sales-Train.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('bigmart-sales-Train.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50h5nswzU4Ev"
      },
      "outputs": [],
      "source": [
        "# statistical info\n",
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hNvEb7-U4Ev"
      },
      "outputs": [],
      "source": [
        "# datatype of attributes\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaeUTVzpU4Ev"
      },
      "outputs": [],
      "source": [
        "# check unique values in dataset\n",
        "df.apply(lambda x: len(x.unique()))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.nunique()"
      ],
      "metadata": {
        "id": "_42rthdgf8Tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF8W0-6yU4Ew"
      },
      "source": [
        "## Preprocessing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SV9erNpvU4Ew"
      },
      "outputs": [],
      "source": [
        "# check for null values\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " df.dtypes"
      ],
      "metadata": {
        "id": "bcYo8g4kgdlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLBTqnB8U4Ew"
      },
      "outputs": [],
      "source": [
        "# check for categorical attributes\n",
        "cat_col = []\n",
        "for x in df.dtypes.index:\n",
        "    if df.dtypes[x] == 'object':\n",
        "        cat_col.append(x)\n",
        "cat_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rn7oFCyQU4Ew"
      },
      "outputs": [],
      "source": [
        "cat_col.remove('Item_Identifier')\n",
        "cat_col.remove('Outlet_Identifier')\n",
        "cat_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJQ-Q58kU4Ex"
      },
      "outputs": [],
      "source": [
        "# print the categorical columns\n",
        "for col in cat_col:\n",
        "    print(col)\n",
        "    print(df[col].value_counts())\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnnCKLazU4Ex"
      },
      "outputs": [],
      "source": [
        "# fill the missing values\n",
        "# item_weight_mean = df.pivot_table(values = \"Item_Weight\", index = 'Item_Identifier')\n",
        "# item_weight_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ar_BZSrU4Ex"
      },
      "outputs": [],
      "source": [
        "# miss_bool = df['Item_Weight'].isnull()\n",
        "# miss_bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWmxAbRpU4Ex"
      },
      "outputs": [],
      "source": [
        "# for i, item in enumerate(df['Item_Identifier']):\n",
        "#     if miss_bool[i]:\n",
        "#         if item in item_weight_mean:\n",
        "#             df['Item_Weight'][i] = item_weight_mean.loc[item]['Item_Weight']\n",
        "#         else:\n",
        "#             df['Item_Weight'][i] = np.mean(df['Item_Weight'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Item_Weight']"
      ],
      "metadata": {
        "id": "sZ-b6stuw2NN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Item_Weight']=df['Item_Weight'].fillna(df['Item_Weight'].mean())"
      ],
      "metadata": {
        "id": "j38t-2BOxLu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8I1Ks31dU4Ey"
      },
      "outputs": [],
      "source": [
        "df['Item_Weight'].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON-8XwTcU4Ey"
      },
      "outputs": [],
      "source": [
        "outlet_size_mode = df.pivot_table(values='Outlet_Size', columns='Outlet_Type', aggfunc=(lambda x: x.mode()[0]))\n",
        "outlet_size_mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outlet_size_mode['Grocery Store']"
      ],
      "metadata": {
        "id": "FB_mKjyUz95i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# finding the mode in each category\n",
        "mode_val = df.groupby('Outlet_Type')['Outlet_Size'].agg(pd.Series.mode)\n",
        "mode_val"
      ],
      "metadata": {
        "id": "sYLG6UNS55V3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# filling the null values with mode of each category\n",
        "df['Outlet_Size'].fillna(df.groupby('Outlet_Type')['Outlet_Size'].transform(lambda x: x.mode()[0]))\n"
      ],
      "metadata": {
        "id": "pX3CmCgw9G3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLcFO47HU4Ey"
      },
      "outputs": [],
      "source": [
        "miss_bool = df['Outlet_Size'].isnull()\n",
        "miss_bool\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[miss_bool, 'Outlet_Size'] = df.loc[miss_bool, 'Outlet_Type'].apply(lambda x: outlet_size_mode[x])"
      ],
      "metadata": {
        "id": "eT_zdTKf-kGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[miss_bool, 'Outlet_Size']"
      ],
      "metadata": {
        "id": "QYz5DjKjzTAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVisMkx3U4Ey"
      },
      "outputs": [],
      "source": [
        "df['Outlet_Size'].isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDy5M1F8U4Ez"
      },
      "outputs": [],
      "source": [
        "sum(df['Item_Visibility']==0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2jgJH6TU4Ez"
      },
      "outputs": [],
      "source": [
        "# replace zeros with mean\n",
        "df.loc[:, 'Item_Visibility'].replace([0], [df['Item_Visibility'].mean()], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e979-fctU4Ez"
      },
      "outputs": [],
      "source": [
        "sum(df['Item_Visibility']==0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdeM2CphU4Ez"
      },
      "outputs": [],
      "source": [
        "# combine item fat content\n",
        "df['Item_Fat_Content'] = df['Item_Fat_Content'].replace({'LF':'Low Fat', 'reg':'Regular', 'low fat':'Low Fat'})\n",
        "df['Item_Fat_Content'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6Xk4BvRU4E0"
      },
      "source": [
        "## Creation of New Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8G-sE22cU4E0"
      },
      "outputs": [],
      "source": [
        "df['New_Item_Type'] = df['Item_Identifier'].apply(lambda x: x[:2])\n",
        "df['New_Item_Type']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)"
      ],
      "metadata": {
        "id": "mcN2lpghEL_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqdHcl2MU4E0"
      },
      "outputs": [],
      "source": [
        "df['New_Item_Type'] = df['New_Item_Type'].map({'FD':'Food', 'NC':'Non-Consumable', 'DR':'Drinks'}) # or replace function can be used\n",
        "df['New_Item_Type'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91EhcbS5U4E0"
      },
      "outputs": [],
      "source": [
        "df.loc[df['New_Item_Type']=='Non-Consumable', 'Item_Fat_Content'] = 'Non-Edible'\n",
        "df['Item_Fat_Content'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DG9axgHU4E0"
      },
      "outputs": [],
      "source": [
        "# create small values for establishment year\n",
        "df['Outlet_Years'] = 2013 - df['Outlet_Establishment_Year'] # as the dataset collected in year 2013, create a column with smaller valyues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2VUnG9tU4E1"
      },
      "outputs": [],
      "source": [
        "df['Outlet_Years']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LlwT8O0CU4E1"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kvjewx0rU4E1"
      },
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "sns.scatterplot(data=df, x='Item_Weight', y='Item_Outlet_Sales',  ax=axes[0,0])\n",
        "\n",
        "sns.stripplot(data=df, x='Outlet_Size', y='Item_Outlet_Sales', ax=axes[0,1])\n",
        "# axes[0,1].set_title('Day Vs. Total bill')\n",
        "\n",
        "sns.boxplot(data=df, x=\"Item_Fat_Content\", y=\"Item_Outlet_Sales\", ax=axes[1,0])\n",
        "# axes[1,0].set_title('Day Vs. Total bill')\n",
        "\n",
        "sns.swarmplot(data=df, x='Outlet_Location_Type', y='Item_Outlet_Sales', ax=axes[1,1]);\n",
        "# axes[1,1].set_title('Tip Vs. Total bill');"
      ],
      "metadata": {
        "id": "Ho-d4R7EKyXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18,6))\n",
        "sns.distplot(df['Item_Weight'], ax=ax1)\n",
        "sns.distplot(df['Item_Visibility'], ax=ax2)\n",
        "sns.distplot(df['Item_MRP'], ax=ax3)"
      ],
      "metadata": {
        "id": "JT3Oyi2kJnh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5P0PYd0U4E1"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['Item_Weight'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mb4wbGMhU4E2"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['Item_Visibility'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ry1tfVMMU4E2"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['Item_MRP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bKFWgWzEU4E2"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['Item_Outlet_Sales'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "\n",
        "scale=StandardScaler()\n",
        "reshaped_vals = np.array(df['Item_Outlet_Sales']).reshape(-1,1)\n",
        "df['Item_Outlet_Sales'] = scale.fit_transform(reshaped_vals)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9hnsK2Z5EyhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Item_Outlet_Sales']"
      ],
      "metadata": {
        "id": "2T9b8orSGP0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(df['Item_Outlet_Sales'])"
      ],
      "metadata": {
        "id": "sIYQXwY2Flwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hDhlv6BU4E2"
      },
      "outputs": [],
      "source": [
        "# log transformation\n",
        "df['Item_Outlet_Sales'] = np.log(1+df['Item_Outlet_Sales'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jMA5pnHU4E2"
      },
      "outputs": [],
      "source": [
        "sns.distplot(df['Item_Outlet_Sales'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwcTRBrSU4E2"
      },
      "outputs": [],
      "source": [
        "sns.countplot(df[\"Item_Fat_Content\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36i1y_vpU4E2"
      },
      "outputs": [],
      "source": [
        "# plt.figure(figsize=(15,5))\n",
        "lab = list(df['Item_Type'].unique())\n",
        "chart = sns.countplot(df[\"Item_Type\"])\n",
        "chart.set_xticklabels(labels=lab, rotation=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJeXf0soU4E2"
      },
      "outputs": [],
      "source": [
        "sns.countplot(df['Outlet_Establishment_Year'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzfVDcDbU4E3"
      },
      "outputs": [],
      "source": [
        "sns.countplot(df['Outlet_Size'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAxF1XrYU4E3"
      },
      "outputs": [],
      "source": [
        "sns.countplot(df['Outlet_Location_Type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VG_GaBhoU4E3"
      },
      "outputs": [],
      "source": [
        "sns.countplot(df['Outlet_Type'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnBii6zWU4E3"
      },
      "source": [
        "## Coorelation Matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfEyaKgKU4E3"
      },
      "outputs": [],
      "source": [
        "corr = df.corr()\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG1uPLnWU4E3"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hC6eNjeyU4E3"
      },
      "source": [
        "## Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmOxAl44U4E3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['Outlet'] = le.fit_transform(df['Outlet_Identifier'])\n",
        "cat_col = ['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type', 'New_Item_Type']\n",
        "for col in cat_col:\n",
        "    df[col] = le.fit_transform(df[col])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pOjSXnKU4E3"
      },
      "source": [
        "## Onehot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJm5A5x-U4E3"
      },
      "outputs": [],
      "source": [
        "df = pd.get_dummies(df, columns=['Item_Fat_Content', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type', 'New_Item_Type'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChUBRVSWU4E4"
      },
      "source": [
        "## Input Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9n5O4_xU4E4"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=['Outlet_Establishment_Year', 'Item_Identifier', 'Outlet_Identifier', 'Item_Outlet_Sales'])\n",
        "y = df['Item_Outlet_Sales']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a72gaqJFU4E4"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p426cJknU4E4"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error ,classification_report\n",
        "\n",
        "def train(model, X, y):\n",
        "    # train the model\n",
        "    model.fit(X, y)\n",
        "\n",
        "    # predict the training set\n",
        "    pred = model.predict(X)\n",
        "\n",
        "    # perform cross-validation\n",
        "    cv_score = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n",
        "    cv_score = np.abs(np.mean(cv_score))\n",
        "\n",
        "    print(\"Model Report\")\n",
        "    print(\"MSE:\",mean_squared_error(y,pred))\n",
        "    print(\"CV Score:\", cv_score)\n",
        "    print(classification_report(y, pred))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iwKJOv3x3fHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM21cqUJU4E4"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "model = LinearRegression(normalize=True)\n",
        "train(model, X, y)\n",
        "coef = pd.Series(model.coef_, X.columns).sort_values()\n",
        "coef.plot(kind='bar', title=\"Model Coefficients\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwDu0lWTU4E4"
      },
      "outputs": [],
      "source": [
        "model = Ridge(normalize=True)\n",
        "train(model, X, y)\n",
        "coef = pd.Series(model.coef_, X.columns).sort_values()\n",
        "coef.plot(kind='bar', title=\"Model Coefficients\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUHikBBXU4E4"
      },
      "outputs": [],
      "source": [
        "model = Lasso()\n",
        "train(model, X, y)\n",
        "coef = pd.Series(model.coef_, X.columns).sort_values()\n",
        "coef.plot(kind='bar', title=\"Model Coefficients\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XU8hnZWPU4E4"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "model = DecisionTreeRegressor()\n",
        "train(model, X, y)\n",
        "coef = pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)\n",
        "coef.plot(kind='bar', title=\"Feature Importance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOI5deKtU4E4"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model = RandomForestRegressor()\n",
        "train(model, X, y)\n",
        "coef = pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)\n",
        "coef.plot(kind='bar', title=\"Feature Importance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lSiKHAuAU4E5"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "model = ExtraTreesRegressor()\n",
        "train(model, X, y)\n",
        "coef = pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)\n",
        "coef.plot(kind='bar', title=\"Feature Importance\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3H3-3wiU4E5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtNWnlJUU4E5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQtHfyN0U4E5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACMJt9N0U4E5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}